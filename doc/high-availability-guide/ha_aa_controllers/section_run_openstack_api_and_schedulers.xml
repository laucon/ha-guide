<?xml version="1.0" encoding="UTF-8"?>
<section xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  version="5.0"
  xml:id="_run_openstack_api_and_schedulers">
  <title>Run OpenStack API and schedulers</title>
  <section xml:id="_api_services">
    <title>API services</title>
    <para>All OpenStack projects have an API service for controlling all the
      resources in the Cloud. In active/active mode, the most common setup is
      to scale out these services on at least two nodes and to use load balancing
      and a virtual IP address (with <application>HAProxy</application> and
      <application>Keepalived</application> in this setup).</para>
    <para>To use highly available and scalable API services, we need to
      ensure that:</para>
    <itemizedlist>
      <listitem>
        <para>You use virtual IP addresses when configuring OpenStack Identity
          endpoints.
        </para>
      </listitem>
      <listitem>
        <para>All OpenStack configuration files should refer to virtual
          IP addresses.</para>
      </listitem>
    </itemizedlist>
    <note>
      <para>The monitor check is quite simple since it just establishes a TCP
        connection to the API port. Comparing to the active/passive mode using
        <application>Corosync</application> and resource agents,
        we do not check if the service is actually running. That is why all
        OpenStack API services should be monitored by another tool, for example
        <application>Nagios</application>.</para>
    </note>
  </section>
  <section xml:id="_schedulers">
    <title>Schedulers</title>
    <para>OpenStack schedulers are used to determine how to dispatch compute,
      network, and volume requests. The most common setup is to use RabbitMQ as a
      messaging system. Those services are connected to the messaging back end
      and can scale out:</para>
    <itemizedlist>
      <listitem>
        <para><systemitem class="service">nova-scheduler</systemitem></para>
      </listitem>
      <listitem>
        <para><systemitem class="service">nova-conductor</systemitem></para>
      </listitem>
      <listitem>
        <para><systemitem class="service">cinder-scheduler</systemitem></para>
      </listitem>
      <listitem>
        <para><systemitem class="service">neutron-server</systemitem></para>
      </listitem>
      <listitem>
        <para><systemitem class="service">ceilometer-collector</systemitem></para>
      </listitem>
      <listitem>
        <para><systemitem class="service">heat-engine</systemitem></para>
      </listitem>
    </itemizedlist>
    <para>Please refer to the <link linkend="s-rabbitmq">RabbitMQ section</link>
      for configuring these services with multiple messaging servers.</para>
  </section>
  <section xml:id="_ceilometer_central">
    <title>Telemetry Central agent</title>
    <para>The Telemetry Central agent can be configured to partition its
      polling workload between multiple agents, enabling high availability.
      Please refer to <link xlink:href="http://docs.openstack.org/admin-guide-cloud/telemetry-data-collection.html#support-for-ha-deployment-of-the-central-and-compute-agent-services">
      this section</link> of the <citetitle>OpenStack Cloud Administrator Guide</citetitle>
      for the requirements and implementation details of this configuration.</para>
  </section>
</section>
